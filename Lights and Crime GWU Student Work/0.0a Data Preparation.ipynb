{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0a Data Preparation\n",
    "Garrett Eason, Chris Broll, Shilpa Rajbhandari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages \n",
    "import pandas as pd\n",
    "!pip install openpyxl\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import datetime as dt\n",
    "\n",
    "#%% Locations\n",
    "Windows = 'C:/Users/Sade/Documents/GitHub/lights-and-crime/Lights and Crime Garrett/Data'\n",
    "Linux = '/home/sade/Desktop/Git Cloned Repos/lights-and-crime/Lights and Crime Garrett/Data'\n",
    "\n",
    "choice = Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Data\n",
    "Acquired from:<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2017<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2016<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2015<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2014<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2013<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2012<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2011<br>\n",
    "http://opendata.dc.gov/datasets/crime-incidents-in-2010<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df17 = pd.read_csv('Crime_Incidents_in_2017.csv')\n",
    "df16 = pd.read_csv('Crime_Incidents_in_2016.csv')\n",
    "df15 = pd.read_csv('Crime_Incidents_in_2015.csv')\n",
    "df14 = pd.read_csv('Crime_Incidents_in_2014.csv')\n",
    "df13 = pd.read_csv('Crime_Incidents_in_2013.csv')\n",
    "df12 = pd.read_csv('Crime_Incidents_in_2012.csv')\n",
    "df11 = pd.read_csv('Crime_Incidents_in_2011.csv')\n",
    "df10 = pd.read_csv('Crime_Incidents_in_2010.csv')\n",
    "\n",
    "crimes = pd.concat([df17, df16, df15, df14, df13, df12, df11, df10], axis=0, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iSlims and City Work Data\n",
    "Acquired from:<br>\n",
    "https://github.com/thelabdc/lights-and-crime/tree/master/data<br>\n",
    "http://opendata.dc.gov/datasets/cityworks-workorders<br>\n",
    "\n",
    "*Note: Be careful about citywork data and Github, the data set is too lage to upload all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up iSlims and City Work Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wo = pd.read_excel(choice + '/islims_workorders.xlsx')\n",
    "de = pd.read_excel(choice + '/islims_workorders_detail.xlsx')\n",
    "iv = pd.read_excel(choice + '/islims_inventory.xlsx')\n",
    "fc = pd.read_excel(choice + '/islims_failure_codes.xlsx')\n",
    "CW = pd.read_csv(choice + '/Cityworks_Workorders.csv') # Will need to add this dataset (too large for GitHub)\n",
    "\n",
    "#%% Merging and Cleaning Data\n",
    "\n",
    "# Merging work order and details sets on woID\n",
    "wode = pd.merge(wo, de, on='woID')\n",
    "\n",
    "# Merging wode and inventory sets on inventoryID\n",
    "iSlimsa = pd.merge(wode, iv, on='inventoryID')\n",
    "\n",
    "# Merging the GPS coordinates to fill in as many NaN gaps as possible\n",
    "gpsX = iSlimsa['gpscoordinateX_x'].combine_first(iSlimsa['gpscoordinateX_y'])\n",
    "gpsX = gpsX.combine_first(iSlimsa['gpscoordinateX_x'])\n",
    "gpsY = iSlimsa['gpscoordinateY_x'].combine_first(iSlimsa['gpscoordinateY_y'])\n",
    "gpsY = gpsY.combine_first(iSlimsa['gpscoordinateY_x'])\n",
    "\n",
    "# Removing irrelevant variables\n",
    "iSlimsb = iSlimsa.iloc[:,0:18]\n",
    "iSlimsb['gpsX'] = gpsX\n",
    "iSlimsb['gpsY'] = gpsY\n",
    "\n",
    "# final merged dataset\n",
    "iSlimsc = iSlimsb.drop(['gpscoordinateX_x', 'gpscoordinateY_x'], axis = 1)\n",
    "\n",
    "# Throwing out observations without GPS coordinate\n",
    "iSlimsd = iSlimsc.dropna(subset = ['gpsX', 'gpsY'])\n",
    "\n",
    "# Will use codes: 2, 196, 201, 209\n",
    "fc[fc['description'].str.contains('ight')].head()\n",
    "\n",
    "# Filtering by observations with the desired failure codes\n",
    "iSlimse = iSlimsd[iSlimsd['finalresolutionID'].isin([2, 196, 201, 209])]\n",
    "\n",
    "# Filtering by times of interest\n",
    "resolv_t = (iSlimse['resolveddatetime'] > '2007-12-31') & (iSlimse['resolveddatetime'] < '2017-01-01') \n",
    "enter_t = (iSlimse['entereddate_x'] > '2007-12-31') & (iSlimse['entereddate_x'] < '2017-01-01')\n",
    "iSlimsf = iSlimse[resolv_t & enter_t]\n",
    "\n",
    "# Filtering out observations with excessively long completion / late completion times\n",
    "iSlimsg = iSlimsf[(iSlimsf['daysToComplete'] <= 23)]\n",
    "iSlimsg['finalresolutionID'].value_counts()\n",
    "\n",
    "# Dropping duplicate woID's\n",
    "iSlimsh = iSlimsg.drop_duplicates(subset = ['woID'])\n",
    "\n",
    "# Throwing out observations with a GPS coordinate that is too large in magnitude to be possible\n",
    "iSlimsh[['gpsX', 'gpsY']] = iSlimsh[['gpsX', 'gpsY']].apply(pd.to_numeric)\n",
    "iSlims = iSlimsh[iSlimsh['gpsX'] <= 20000 ]\n",
    "iSlims = iSlims[iSlims['gpsY']<= 20000]\n",
    "\n",
    "# Removing 2 observations whos GPS coordinates were entered incorrectly and limiting bounds of GPS coordinates to realistic numbers in the bounds of DC\n",
    "iSlims = iSlims.drop([465076, 144970])\n",
    "iSlims = iSlims[(iSlims['gpsX'] >= 38.7) & (iSlims['gpsX'] <= 39) ]\n",
    "iSlims = iSlims[(iSlims['gpsY'] >= -77.15) & (iSlims['gpsY'] <= -76.90)]\n",
    "# Cutting out close outliers\n",
    "iSlims = iSlims[~((iSlims['gpsX'] >= 38.828) & (iSlims['gpsX'] <= 38.8395) & (iSlims['gpsY'] <= -76.9632) & (iSlims['gpsY'] >= -76.9777))]\n",
    "iSlims = iSlims[~((iSlims['gpsX'] >= 38.955) & (iSlims['gpsX'] <= 38.96) & (iSlims['gpsY'] >= -76.98) & (iSlims['gpsY'] <= -76.97))]\n",
    "iSlims = iSlims.reset_index()\n",
    "del iSlims['index']\n",
    "\n",
    "# For some reason the coordinate system is backwards\n",
    "iSlims[['gpsX', 'gpsY']] = iSlims[['gpsY', 'gpsX']]\n",
    "\n",
    "#%% Merged Ready and Standardized iSlims Data\n",
    "\n",
    "# Standardized iSlims\n",
    "SDiSlims = iSlims[['woID', 'entereddate_x', 'resolveddatetime', 'gpsX', 'gpsY']]\n",
    "SDiSlims.columns = ['WoID', 'WoEntered', 'WoCompleted', 'gpsX', 'gpsY']\n",
    "\n",
    "# Readying City Works Data\n",
    "some_vars = [\"WORKORDERID\",\"WORKORDERCLOSEDDATE\",\"INITIATEDDATE\",\"DESCRIPTION\", \"LATITUDE\", \"LONGITUDE\", \"X\", \"Y\"]\n",
    "CW_1 = CW[CW[\"DESCRIPTION\"]==\"LIGHT POLE LIGHT OUT\"][some_vars]\n",
    "CW_2 = CW[CW[\"DESCRIPTION\"]==\"LIGHT MALFUNCTION\"][some_vars]\n",
    "CW_new = pd.concat([CW_1,CW_2])\n",
    "CW_new = CW_new.sort_values(by=\"INITIATEDDATE\", ascending=False)\n",
    "CW_new = CW_new.reset_index(drop = True)\n",
    "final_vars = [\"WORKORDERID\",\"INITIATEDDATE\", \"WORKORDERCLOSEDDATE\",\"X\", \"Y\"]\n",
    "CW_new = CW_new[final_vars]\n",
    "CW_new.columns = [\"WoID\", \"WoEntered\", \"WoCompleted\", \"gpsX\", \"gpsY\"]\n",
    "CW_new = CW_new[(CW_new['gpsY'] >= 38.7)]\n",
    "\n",
    "#%% Merging iSlims and Citywork\n",
    "Lights = pd.concat([SDiSlims, CW_new], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating Out Night Crimes\n",
    "To avoid exogeneity problems due to sun rise/set times, we will define the following:<br>\n",
    "Night will be defined as the shortest time difference between nautical twilight (21:00 - 5:00 Military time);<br>\n",
    "Day will be defined as the shortest time difference between civil twilight (7:00 - 17:00)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes['REPORT_DAT'] = [dt.datetime.strptime(date, '%Y-%m-%dT%H:%M:%S.%fZ') for date in crimes['REPORT_DAT']]\n",
    "NCR = crimes[(crimes.REPORT_DAT.dt.hour <= 5) | (crimes['REPORT_DAT'].dt.hour > 21)]\n",
    "DCR = crimes[(crimes.REPORT_DAT.dt.hour <= 17) & (crimes['REPORT_DAT'].dt.hour > 7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes.to_excel(choice + '/crimes.xlsx')\n",
    "SDiSlims.to_excel(choice + '/SDiSlims_final.xlsx')\n",
    "NCR.to_excel(choice + '/NCR.xlsx')\n",
    "DCR.to_excel(choice + '/DCR.xlsx')\n",
    "Lights.to_excel(choice + '/Lights.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
